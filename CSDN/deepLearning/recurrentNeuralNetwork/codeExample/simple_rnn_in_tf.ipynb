{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected cross entropy loss if the model:\n",
      "- learns neither dependency: 0.6615632381579821\n",
      "- learns first dependency: 0.5191666997072094\n",
      "- learns both dependency: 0.4544543674493905\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected cross entropy loss if the model:\")\n",
    "print(\"- learns neither dependency:\", -(0.625 * np.log(0.625) + 0.375 * np.log(0.375)))\n",
    "print(\"- learns first dependency:\", \n",
    "      -0.5 * (0.875 * np.log(0.875) + 0.125 * np.log(0.125))\n",
    "      -0.5 * (0.625 * np.log(0.625) + 0.375 * np.log(0.375)))\n",
    "print(\"- learns both dependency:\", \n",
    "      -0.5 * (0.75 * np.log(0.75) + 0.25 * np.log(0.25))\n",
    "      -0.25 * (2 * 0.5 * np.log(0.5) - 0.25 * (0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 5\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size = 1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(raw_date, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_date\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    #partition raw data into batches and stak them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    # do partition \n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i : batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i : batch_partition_length * (i + 1)]\n",
    "    # do epoch\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield(x, y)\n",
    "        \n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'rnn/basic_rnn_cell/Tanh:0' shape=(200, 16) dtype=float32>, <tf.Tensor 'rnn/basic_rnn_cell/Tanh_1:0' shape=(200, 16) dtype=float32>, <tf.Tensor 'rnn/basic_rnn_cell/Tanh_2:0' shape=(200, 16) dtype=float32>, <tf.Tensor 'rnn/basic_rnn_cell/Tanh_3:0' shape=(200, 16) dtype=float32>, <tf.Tensor 'rnn/basic_rnn_cell/Tanh_4:0' shape=(200, 16) dtype=float32>]\n",
      "Tensor(\"rnn/basic_rnn_cell/Tanh_4:0\", shape=(200, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# with tf.variable_scope('rnn_cell'):\n",
    "#     W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "#     b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "# def rnn_cell(rnn_input, state):\n",
    "#     with tf.variable_scope('rnn_cell', reuse=True):\n",
    "#         W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "#         b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "#     return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "    \n",
    "# state = init_state\n",
    "# rnn_outputs = []\n",
    "# for rnn_input in rnn_inputs:\n",
    "#     state = rnn_cell(rnn_input, state)\n",
    "#     rnn_outputs.append(state)\n",
    "# final_state = rnn_outputs[-1]\n",
    "\n",
    "# 上面是原始代码，定义了rnn_cell，然后使用循环的方式对其进行复用，\n",
    "#利用tensorflow简化之后我们可以直接调用BasicRNNCell和static_rnn两个函数实现\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.nn.static_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "print(rnn_outputs)\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \n",
    "         logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object gen_batch at 0x7f6dd8dbb678>\n",
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 100 steps: 0.5886704778671265\n",
      "Average loss at step 200 for last 100 steps: 0.48904190987348556\n",
      "Average loss at step 300 for last 100 steps: 0.48287136524915697\n",
      "Average loss at step 400 for last 100 steps: 0.4804519456624985\n",
      "Average loss at step 500 for last 100 steps: 0.48000637114048006\n",
      "Average loss at step 600 for last 100 steps: 0.47891183793544767\n",
      "Average loss at step 700 for last 100 steps: 0.4779002183675766\n",
      "Average loss at step 800 for last 100 steps: 0.47922206968069075\n",
      "Average loss at step 900 for last 100 steps: 0.4805783089995384\n",
      "<generator object gen_batch at 0x7f6dd8dbb518>\n",
      "\n",
      "EPOCH 1\n",
      "Average loss at step 100 for last 100 steps: 0.4836905121803284\n",
      "Average loss at step 200 for last 100 steps: 0.47686648219823835\n",
      "Average loss at step 300 for last 100 steps: 0.47551822185516357\n",
      "Average loss at step 400 for last 100 steps: 0.4758254483342171\n",
      "Average loss at step 500 for last 100 steps: 0.4751642617583275\n",
      "Average loss at step 600 for last 100 steps: 0.47619022607803346\n",
      "Average loss at step 700 for last 100 steps: 0.47638276576995847\n",
      "Average loss at step 800 for last 100 steps: 0.4778786998987198\n",
      "Average loss at step 900 for last 100 steps: 0.47350735157728197\n",
      "<generator object gen_batch at 0x7f6dd8dbb8e0>\n",
      "\n",
      "EPOCH 2\n",
      "Average loss at step 100 for last 100 steps: 0.48342735528945924\n",
      "Average loss at step 200 for last 100 steps: 0.47590082049369814\n",
      "Average loss at step 300 for last 100 steps: 0.47504865139722824\n",
      "Average loss at step 400 for last 100 steps: 0.47319830030202864\n",
      "Average loss at step 500 for last 100 steps: 0.4722644305229187\n",
      "Average loss at step 600 for last 100 steps: 0.47180556327104567\n",
      "Average loss at step 700 for last 100 steps: 0.47020508229732516\n",
      "Average loss at step 800 for last 100 steps: 0.47277473747730253\n",
      "Average loss at step 900 for last 100 steps: 0.47335544854402545\n",
      "<generator object gen_batch at 0x7f6dd8dbb678>\n",
      "\n",
      "EPOCH 3\n",
      "Average loss at step 100 for last 100 steps: 0.47962687253952024\n",
      "Average loss at step 200 for last 100 steps: 0.4729653179645538\n",
      "Average loss at step 300 for last 100 steps: 0.4684696924686432\n",
      "Average loss at step 400 for last 100 steps: 0.4749476221203804\n",
      "Average loss at step 500 for last 100 steps: 0.4693226271867752\n",
      "Average loss at step 600 for last 100 steps: 0.47078146308660507\n",
      "Average loss at step 700 for last 100 steps: 0.46865280866622927\n",
      "Average loss at step 800 for last 100 steps: 0.46896958082914353\n",
      "Average loss at step 900 for last 100 steps: 0.4719331008195877\n",
      "<generator object gen_batch at 0x7f6dd8dbb518>\n",
      "\n",
      "EPOCH 4\n",
      "Average loss at step 100 for last 100 steps: 0.47956546127796174\n",
      "Average loss at step 200 for last 100 steps: 0.46855053305625916\n",
      "Average loss at step 300 for last 100 steps: 0.46858362019062044\n",
      "Average loss at step 400 for last 100 steps: 0.4679170069098473\n",
      "Average loss at step 500 for last 100 steps: 0.4682816624641418\n",
      "Average loss at step 600 for last 100 steps: 0.4667176327109337\n",
      "Average loss at step 700 for last 100 steps: 0.46710929632186887\n",
      "Average loss at step 800 for last 100 steps: 0.4674223673343658\n",
      "Average loss at step 900 for last 100 steps: 0.46657954156398773\n",
      "<generator object gen_batch at 0x7f6dd8dbb8e0>\n",
      "\n",
      "EPOCH 5\n",
      "Average loss at step 100 for last 100 steps: 0.47464186817407605\n",
      "Average loss at step 200 for last 100 steps: 0.4659984204173088\n",
      "Average loss at step 300 for last 100 steps: 0.4657625213265419\n",
      "Average loss at step 400 for last 100 steps: 0.4682627320289612\n",
      "Average loss at step 500 for last 100 steps: 0.4650429278612137\n",
      "Average loss at step 600 for last 100 steps: 0.4666986608505249\n",
      "Average loss at step 700 for last 100 steps: 0.4638074839115143\n",
      "Average loss at step 800 for last 100 steps: 0.46564254492521284\n",
      "Average loss at step 900 for last 100 steps: 0.4628158888220787\n",
      "<generator object gen_batch at 0x7f6dd8dbb678>\n",
      "\n",
      "EPOCH 6\n",
      "Average loss at step 100 for last 100 steps: 0.47387985765933993\n",
      "Average loss at step 200 for last 100 steps: 0.46584785997867584\n",
      "Average loss at step 300 for last 100 steps: 0.4635065898299217\n",
      "Average loss at step 400 for last 100 steps: 0.4657951444387436\n",
      "Average loss at step 500 for last 100 steps: 0.46396717458963393\n",
      "Average loss at step 600 for last 100 steps: 0.4621760794520378\n",
      "Average loss at step 700 for last 100 steps: 0.4624777543544769\n",
      "Average loss at step 800 for last 100 steps: 0.4626235055923462\n",
      "Average loss at step 900 for last 100 steps: 0.46238711595535276\n",
      "<generator object gen_batch at 0x7f6dd8dbb518>\n",
      "\n",
      "EPOCH 7\n",
      "Average loss at step 100 for last 100 steps: 0.47047441005706786\n",
      "Average loss at step 200 for last 100 steps: 0.46336791664361954\n",
      "Average loss at step 300 for last 100 steps: 0.4613287726044655\n",
      "Average loss at step 400 for last 100 steps: 0.46212357163429263\n",
      "Average loss at step 500 for last 100 steps: 0.46023330360651016\n",
      "Average loss at step 600 for last 100 steps: 0.46029590010643007\n",
      "Average loss at step 700 for last 100 steps: 0.46114850908517835\n",
      "Average loss at step 800 for last 100 steps: 0.46053547382354737\n",
      "Average loss at step 900 for last 100 steps: 0.46017547965049743\n",
      "<generator object gen_batch at 0x7f6dd8dbb8e0>\n",
      "\n",
      "EPOCH 8\n",
      "Average loss at step 100 for last 100 steps: 0.46789534121751786\n",
      "Average loss at step 200 for last 100 steps: 0.46100429505109786\n",
      "Average loss at step 300 for last 100 steps: 0.4603461688756943\n",
      "Average loss at step 400 for last 100 steps: 0.4617107427120209\n",
      "Average loss at step 500 for last 100 steps: 0.46108670622110365\n",
      "Average loss at step 600 for last 100 steps: 0.45847600102424624\n",
      "Average loss at step 700 for last 100 steps: 0.4597319149971008\n",
      "Average loss at step 800 for last 100 steps: 0.4603318506479263\n",
      "Average loss at step 900 for last 100 steps: 0.461778307557106\n",
      "<generator object gen_batch at 0x7f6dd8dbb678>\n",
      "\n",
      "EPOCH 9\n",
      "Average loss at step 100 for last 100 steps: 0.4679246434569359\n",
      "Average loss at step 200 for last 100 steps: 0.45885625571012495\n",
      "Average loss at step 300 for last 100 steps: 0.4591403499245644\n",
      "Average loss at step 400 for last 100 steps: 0.4590956747531891\n",
      "Average loss at step 500 for last 100 steps: 0.46066900849342346\n",
      "Average loss at step 600 for last 100 steps: 0.4577329710125923\n",
      "Average loss at step 700 for last 100 steps: 0.45974335074424744\n",
      "Average loss at step 800 for last 100 steps: 0.4584796878695488\n",
      "Average loss at step 900 for last 100 steps: 0.45832603514194487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6dd6d12b00>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6dd8d454a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            print(epoch)\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _= \\\n",
    "                    sess.run([losses, \n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                            feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 100 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "    return training_losses\n",
    "training_losses = train_network(10, num_steps, state_size=state_size)\n",
    "plt.plot(training_losses)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
